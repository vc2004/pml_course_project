---
title: "Prediction and Analysis on Weight Lifting Exercise Dataset"
author: "Liang Dong"
date: "27 December 2015"
output:
  html_document:
    highlights: tango
    theme: readable
    highlight: tango
    toc: yes
    keep_md: true
---

# Executive Summary

This is the project report for coursera practical machine learning course.

This report focus on data from Weight Lifting Exercise. Among the 5 classes of weight lifting (Class A,B,C,D,E), only Class A is the correct training method, while others are training method with common mistakes. The report use other variables in the dataset to predict the class of weight lifting.

More information is available from Weight Lifting Exercises Dataset section in following website: http://groupware.les.inf.puc-rio.br/har

# Data Pre-processing

Load the required ggplot2 and caret library for prediction.

```{r}
library(ggplot2)
library(caret)
library(randomForest)
```

Download the dataset and pre-process the data. Some of the data are missing, so it will be marked as NA.

```{r}
pml_train_url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pml_test_url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if (!file.exists("pml-training.csv")) {
    download.file(pml_train_url, destfile="pml-training.csv", method="curl")
}
if (!file.exists("pml-testing.csv")) {
    download.file(pml_test_url, destfile="pml-testing.csv", method="curl")
}

pml_training <- read.csv("pml-training.csv", na.strings=c("NA",""))
pml_testing <- read.csv("pml-testing.csv", na.strings=c("NA",""))
```

The dimension of the training set is 19622 rows with 160 columns, the testing set is 20 rows with the same columns numbers. 

```{r}
dim(pml_training)
dim(pml_testing)
```

First of all, the training data has to be further partitioned into training and testing set, which the testing set is used for characterising and cross-validating the performance of the prediction other than the final prediction set. Also, to achieve the reproducibility, the seed should be set to guarantee that goal.

70% percent of the training data is used for training, while the remaining 30% is used for testing.

```{r}
set.seed(20151227)

inTrain <- createDataPartition(pml_training$classe, p=0.70, list=FALSE)
training <- pml_training[inTrain, ]
testing <- pml_training[-inTrain, ]
```

From the perspective weight lifting domain knowledge, the first several columns which are literally the row numbers, username, timestamps, should be excluded from the features set. 

```{r}
training <- training[, c(-1:-5)]
testing <- testing[, c(-1:-5)]
```

Also the near zero variable columns and mostly NA columns should be also removed from data set. The columns which kept are NA not exceeding 90%.

```{r}
nzv_train <- nearZeroVar(training)
training <- training[, -nzv_train]
testing<- testing[, -nzv_train]

NA90p <- sapply(training, function(x) mean(is.na(x))) < 0.90
training <- training[, NA90p==TRUE]
testing <- testing[, NA90p==TRUE]
```

# Random Forest

The random forest is tried as the first algorithm. The result is shown as below, the error rate on training data is 99.7% and the Out of Sample Error is 0.3%.

```{r}
fit <- randomForest(classe ~ ., data = training)
fit
```

# Cross Validation

To cross validate the result, the testing set is predicted and compared the original result. The accuracy is 99.63%, which is pretty good and consistent with the training set result.

```{r}
testing_prediction <- predict(fit, newdata=testing)
confusionMatrix(testing$classe, testing_prediction)
```

# Testset Prediction

Since the Random Forest has already generated a very good result and fitted model, and it has proven performance in the cross validation, it will be used in the prediction. Transform the test set into the same data format as the training set to fit the prediction model. 

```{r}
pml_testing <- pml_testing[, c(-1:-5)]
pml_testing <- pml_testing[, -nzv_train]
pml_testing <- pml_testing[, NA90p==TRUE]

final_predict <- predict(fit, newdata=pml_testing)
```

Use the code given in the project submission to write the final prediction to file and submit.


